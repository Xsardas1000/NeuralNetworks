{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 3 \"Определение ключевых точек лица\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Филин Максим Дмитриевич"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Рассматривал различные архитектуры с полносвязными слоями и сверточные сети\n",
    "Лучший результат - network4 - 7.15\n",
    "Сверточные пока дают результат хуже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя датасет из архива решите задачу регрессии для поиска 68-ми ключевых точек лица. \n",
    "\n",
    "Для обучения и валидации используйте изображения и разметку из папок train и test соответственно.\n",
    "\n",
    "Попробуйте сети глубины 1 и 2 и разные активации (ELU, RELU и sigmoid).\n",
    "Для каждой архитектуры постройте графики для функции потерь на train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image name: 109.jpeg\n",
      "Landmarks shape: (68, 2)\n",
      "First 4 Landmarks: [[ 7. 41.]\n",
      " [ 8. 51.]\n",
      " [10. 60.]\n",
      " [13. 70.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.nn import MSELoss, Sequential, Linear, Sigmoid, Tanh, ELU\n",
    "from torch.autograd import Variable\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "landmarks_frame = pd.read_csv('dataset/train/face_landmarks.csv')\n",
    "\n",
    "n = 100\n",
    "img_name = landmarks_frame.ix[n, 0]\n",
    "landmarks = landmarks_frame.ix[n, 1:].as_matrix().astype('float')\n",
    "landmarks = landmarks.reshape(-1, 2)\n",
    "\n",
    "print('Image name: {}'.format(img_name))\n",
    "print('Landmarks shape: {}'.format(landmarks.shape))\n",
    "print('First 4 Landmarks: {}'.format(landmarks[:4]))\n",
    "\n",
    "def show_landmarks(image, landmarks):\n",
    "    \"\"\"Show image with landmarks\"\"\"\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='red', cmap='rgb')\n",
    "    plt.pause(0.001)  \n",
    "\n",
    "plt.figure()\n",
    "show_landmarks(io.imread(os.path.join('dataset/train/', img_name)),\n",
    "               landmarks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6221, 137)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>part_0_x</th>\n",
       "      <th>part_0_y</th>\n",
       "      <th>part_1_x</th>\n",
       "      <th>part_1_y</th>\n",
       "      <th>part_2_x</th>\n",
       "      <th>part_2_y</th>\n",
       "      <th>part_3_x</th>\n",
       "      <th>part_3_y</th>\n",
       "      <th>part_4_x</th>\n",
       "      <th>...</th>\n",
       "      <th>part_63_x</th>\n",
       "      <th>part_63_y</th>\n",
       "      <th>part_64_x</th>\n",
       "      <th>part_64_y</th>\n",
       "      <th>part_65_x</th>\n",
       "      <th>part_65_y</th>\n",
       "      <th>part_66_x</th>\n",
       "      <th>part_66_y</th>\n",
       "      <th>part_67_x</th>\n",
       "      <th>part_67_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpeg</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>78</td>\n",
       "      <td>56</td>\n",
       "      <td>80</td>\n",
       "      <td>47</td>\n",
       "      <td>77</td>\n",
       "      <td>43</td>\n",
       "      <td>77</td>\n",
       "      <td>39</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpeg</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>62</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>74</td>\n",
       "      <td>53</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>77</td>\n",
       "      <td>46</td>\n",
       "      <td>77</td>\n",
       "      <td>42</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.jpeg</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>70</td>\n",
       "      <td>56</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>72</td>\n",
       "      <td>47</td>\n",
       "      <td>72</td>\n",
       "      <td>43</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.jpeg</td>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "      <td>13</td>\n",
       "      <td>51</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>70</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "      <td>61</td>\n",
       "      <td>71</td>\n",
       "      <td>54</td>\n",
       "      <td>73</td>\n",
       "      <td>51</td>\n",
       "      <td>73</td>\n",
       "      <td>47</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000.jpeg</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>65</td>\n",
       "      <td>62</td>\n",
       "      <td>70</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name  part_0_x  part_0_y  part_1_x  part_1_y  part_2_x  part_2_y  \\\n",
       "0     0.jpeg        10        43         9        53         8        64   \n",
       "1     1.jpeg         9        32         8        42         9        52   \n",
       "2    10.jpeg         4        34         5        44         6        54   \n",
       "3   100.jpeg        12        41        13        51        15        60   \n",
       "4  1000.jpeg         8        46         9        55        10        64   \n",
       "\n",
       "   part_3_x  part_3_y  part_4_x    ...      part_63_x  part_63_y  part_64_x  \\\n",
       "0         8        74        10    ...             47         78         56   \n",
       "1        12        62        15    ...             48         74         53   \n",
       "2         9        64        14    ...             50         70         56   \n",
       "3        17        70        21    ...             54         72         61   \n",
       "4        12        73        16    ...             54         65         62   \n",
       "\n",
       "   part_64_y  part_65_x  part_65_y  part_66_x  part_66_y  part_67_x  part_67_y  \n",
       "0         80         47         77         43         77         39         77  \n",
       "1         76         48         77         46         77         42         77  \n",
       "2         72         50         72         47         72         43         72  \n",
       "3         71         54         73         51         73         47         73  \n",
       "4         70         54         72         50         72         46         71  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(landmarks_frame.shape)\n",
    "landmarks_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_landmarks_batch(sample_batch, y_pred=None):\n",
    "    \"\"\"Show image with landmarks for a batch of samples.\"\"\"\n",
    "    images_batch, landmarks_batch = \\\n",
    "            sample_batch['image'], sample_batch['landmarks']\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "\n",
    "    grid = utils.make_grid(images_batch)\n",
    "    print(images_batch.numpy().shape)\n",
    "    plt.imshow(grid.numpy().transpose(1,0,2).reshape(im_size, -1), cmap=\"gray\")\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size,\n",
    "                    landmarks_batch[i, :, 1].numpy(),\n",
    "                    s=10, marker='.', c='r', label='Real')\n",
    "\n",
    "    if type(y_pred) != type(None):\n",
    "        for i in range(batch_size):\n",
    "            plt.scatter(y_pred[i, :, 0] + i * im_size,\n",
    "                        y_pred[i, :, 1],\n",
    "                        s=10, marker='.', c='b',  label='Prediction')\n",
    "        plt.title('Batch from dataloader')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceLandmarksDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:].as_matrix().astype('float')\n",
    "        landmarks = landmarks.reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'landmarks': torch.from_numpy(landmarks)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FaceLandmarksDataset(csv_file='dataset/train/face_landmarks.csv',\n",
    "                                     root_dir='dataset/train',\n",
    "                                     transform=ToTensor()\n",
    "                                     )\n",
    "\n",
    "test_dataset = FaceLandmarksDataset(csv_file='dataset/test/face_landmarks.csv',\n",
    "                                     root_dir='dataset/test',\n",
    "                                     transform=ToTensor()\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64,\n",
    "                        shuffle=True, num_workers=6)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64,\n",
    "                        shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype=torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 96, 96])\n",
      "torch.Size([64, 1, 68, 2])\n"
     ]
    }
   ],
   "source": [
    "for sample in train_dataloader:\n",
    "    X = sample['image']\n",
    "    #X = Variable(X.view(X.shape[0], -1)).type(dtype)\n",
    "    X = Variable(X)\n",
    "    X = X[:, np.newaxis, :, :]\n",
    "    \n",
    "    y = sample['landmarks']\n",
    "    #y = Variable(y.view(y.shape[0], -1)).type(dtype)\n",
    "    y = Variable(y)\n",
    "    y = y[:, np.newaxis, :, :]\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = torch.nn.MSELoss().cuda()\n",
    "\n",
    "\n",
    "def train(network, epochs, learning_rate, loss=torch.nn.MSELoss().cuda(), optim=torch.optim.Adam):\n",
    "    train_loss_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    optimizer = optim(network.parameters(), lr=learning_rate)\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            losses = []\n",
    "            accuracies = []\n",
    "            for sample in train_dataloader:\n",
    "                X = sample['image']\n",
    "                X = Variable(X.view(X.shape[0], -1)).type(dtype)\n",
    "                y = sample['landmarks']\n",
    "                y = Variable(y.view(y.shape[0], -1)).type(dtype)\n",
    "\n",
    "                prediction = network(X)\n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.data[0])\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss_batch.backward()\n",
    "                optimizer.step()\n",
    "  \n",
    "            train_loss_epochs.append(np.mean(losses))\n",
    "            losses = []    \n",
    "            for sample in test_dataloader:\n",
    "                X = sample['image']\n",
    "                X = Variable(X.view(X.shape[0], -1)).type(dtype)\n",
    "                y = sample['landmarks']\n",
    "                y = Variable(y.view(y.shape[0], -1)).type(dtype)\n",
    "                \n",
    "                prediction = network(X)\n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.data[0])\n",
    "                \n",
    "            test_loss_epochs.append(np.mean(losses))\n",
    "            sys.stdout.write('\\rEpoch {0}... (Train/Test) MSE: {1:.3f}/{2:.3f}'.format(\n",
    "                        epoch, train_loss_epochs[-1], test_loss_epochs[-1]))\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(train_loss_epochs[1:], label='Train')\n",
    "    plt.plot(test_loss_epochs[1:], label='Test')\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.legend(loc=0, fontsize=16)\n",
    "    plt.grid('on')\n",
    "    plt.show()\n",
    "    return test_loss_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(network):\n",
    "    loss = mse_loss = torch.nn.MSELoss().cuda()\n",
    "    losses = []   \n",
    "    for sample in test_dataloader:\n",
    "        X = sample['image']\n",
    "        X = Variable(X.view(X.shape[0], -1)).type(dtype)\n",
    "        y = sample['landmarks']\n",
    "        y = Variable(y.view(y.shape[0], -1)).type(dtype)\n",
    "\n",
    "        prediction = network(X)\n",
    "        loss_batch = loss(prediction, y)\n",
    "        losses.append(loss_batch.data[0])  \n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_network(network, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(network, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор архитектуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = 1 * 96 * 96  # C=1 because of black-and-white images\n",
    "D_out = 2 * 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1 = Sequential(\n",
    "          Linear(D_in, 1000),\n",
    "          Sigmoid(),\n",
    "          Linear(1000, 1000),\n",
    "          Sigmoid(),\n",
    "          Linear(1000, D_out)\n",
    "        ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(network1, 10, 0.001, loss=mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2 = Sequential(\n",
    "          Linear(D_in, 512),\n",
    "          Tanh(),\n",
    "          Linear(512, 512),\n",
    "          Tanh(),\n",
    "          Linear(512, D_out)\n",
    "        ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(network2, 10, 0.001, loss=mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(Linear(1 * 96 * 96, 200), Tanh(),\n",
    "               Linear(200, 2 * 68)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, 10, 0.001, loss=mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network3 = Sequential(\n",
    "              Linear(D_in, 1000),\n",
    "              ELU(0.1),\n",
    "              Linear(1000, 1000),\n",
    "              ELU(0.1),\n",
    "              Linear(1000, 1000),\n",
    "              ELU(0.1),\n",
    "              Linear(1000, D_out)\n",
    "           ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(network3, 20, 1e-4, loss=mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network3 = Sequential(\n",
    "              Linear(D_in, 512),\n",
    "              ELU(),\n",
    "              Linear(512, 1000),\n",
    "              ELU(),\n",
    "              Linear(1000, 512),\n",
    "              ELU(),\n",
    "              Linear(512, D_out)\n",
    "           ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(network3, 40, 1e-4, loss=mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network4 = Sequential(\n",
    "              Linear(D_in, 512),\n",
    "              nn.BatchNorm2d(512),\n",
    "              ELU(),\n",
    "              Linear(512, 1000),\n",
    "              nn.BatchNorm2d(1000),\n",
    "              ELU(),\n",
    "              Linear(1000, 512),\n",
    "              nn.BatchNorm2d(512),\n",
    "              ELU(),\n",
    "              Linear(512, D_out)\n",
    "           ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(network4, 20, 1e-4, loss=mse_loss) # 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network5 = Sequential(\n",
    "              Linear(D_in, 512),\n",
    "              nn.BatchNorm2d(512),\n",
    "              nn.ReLU(),\n",
    "              Linear(512, 512),\n",
    "              nn.BatchNorm2d(512),\n",
    "              nn.ReLU(),\n",
    "              Linear(512, 512),\n",
    "              nn.BatchNorm2d(512),\n",
    "              nn.ReLU(),\n",
    "              Linear(512, 512),\n",
    "              nn.BatchNorm2d(512),\n",
    "              nn.ReLU(),\n",
    "              Linear(512, D_out)\n",
    "           ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = train(network5, 200, 1e-4, loss=mse_loss) # 150 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_loss(network5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_network(network5, './network5_5.76.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ConvNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 96\n",
    "channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = torch.nn.MSELoss().cuda()\n",
    "dtype=torch.cuda.FloatTensor\n",
    "\n",
    "def train(network, epochs, learning_rate, loss=torch.nn.MSELoss().cuda(), optim=torch.optim.Adam):\n",
    "    train_loss_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    optimizer = optim(network.parameters(), lr=learning_rate)\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            losses = []\n",
    "            accuracies = []\n",
    "            for sample in train_dataloader:\n",
    "                X = sample['image']\n",
    "                #X = Variable(X.view(X.shape[0], -1)).type(dtype)\n",
    "                y = sample['landmarks']\n",
    "                #y = Variable(y.view(y.shape[0], -1)).type(dtype)\n",
    "                \n",
    "                X = Variable(X)\n",
    "                X = X[:, np.newaxis, :, :].type(dtype)\n",
    "                \n",
    "                y = Variable(y)\n",
    "                y = y[:, np.newaxis, :, :].type(dtype)\n",
    "\n",
    "                prediction = network(X)\n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.data[0])\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss_batch.backward()\n",
    "                optimizer.step()\n",
    "  \n",
    "            train_loss_epochs.append(np.mean(losses))\n",
    "            losses = []    \n",
    "            for sample in test_dataloader:\n",
    "                X = sample['image']\n",
    "                #X = Variable(X.view(X.shape[0], -1)).type(dtype)\n",
    "                y = sample['landmarks']\n",
    "                #y = Variable(y.view(y.shape[0], -1)).type(dtype)\n",
    "                \n",
    "                X = Variable(X)\n",
    "                X = X[:, np.newaxis, :, :].type(dtype)\n",
    "                \n",
    "                y = Variable(y)\n",
    "                y = y[:, np.newaxis, :, :].type(dtype)\n",
    "                \n",
    "                \n",
    "                prediction = network(X)\n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.data[0])\n",
    "                \n",
    "            test_loss_epochs.append(np.mean(losses))\n",
    "            sys.stdout.write('\\rEpoch {0}... (Train/Test) MSE: {1:.3f}/{2:.3f}'.format(\n",
    "                        epoch, train_loss_epochs[-1], test_loss_epochs[-1]))\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(train_loss_epochs[1:], label='Train')\n",
    "    plt.plot(test_loss_epochs[1:], label='Test')\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.legend(loc=0, fontsize=16)\n",
    "    plt.grid('on')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input -> 8 Conv 3x3 -> ReLU -> maxpool -> 16 Conv 3x3 -> ReLU -> ravel -> Linear -> LogSoftmax\n",
    "class Conv1(nn.Module):\n",
    "    def __init__(self, input_size, input_channels):\n",
    "        super(Conv1, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(nn.Conv2d(input_channels, 8, (3, 3), padding=1),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2),\n",
    "                                         nn.Conv2d(8, 16, (3, 3), padding=1),\n",
    "                                         nn.ReLU(),\n",
    "                                        )\n",
    "        self.linear_layers = nn.Sequential(nn.Linear(int(input_size * input_size / (4) * 16), D_out),\n",
    "                                           nn.LogSoftmax())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = Conv1(image_size, channels).cuda()\n",
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train(conv1, 50, 1e-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "net2 = NeuralNet(\n",
    "    layers=[\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),\n",
    "        ('pool1', layers.MaxPool2DLayer),\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('pool2', layers.MaxPool2DLayer),\n",
    "        ('conv3', layers.Conv2DLayer),\n",
    "        ('pool3', layers.MaxPool2DLayer),\n",
    "        ('hidden4', layers.DenseLayer),\n",
    "        ('hidden5', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    input_shape=(None, 1, 96, 96),\n",
    "    conv1_num_filters=32, conv1_filter_size=(3, 3), pool1_pool_size=(2, 2),\n",
    "    conv2_num_filters=64, conv2_filter_size=(2, 2), pool2_pool_size=(2, 2),\n",
    "    conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_pool_size=(2, 2),\n",
    "    hidden4_num_units=500, hidden5_num_units=500,\n",
    "    output_num_units=30, output_nonlinearity=None,\n",
    "\n",
    "    update_learning_rate=0.01,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=True,\n",
    "    max_epochs=1000,\n",
    "    verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2(nn.Module):\n",
    "    def __init__(self, input_size, input_channels):\n",
    "        super(Conv2, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(nn.Conv2d(input_channels, 32, (3, 3)),\n",
    "                                         nn.ELU(),\n",
    "                                         nn.MaxPool2d(2),\n",
    "                                         nn.Conv2d(32, 64, (2, 2)),\n",
    "                                         nn.ELU(),\n",
    "                                         nn.MaxPool2d(2),\n",
    "                                         nn.Conv2d(64, 128, (2, 2)),\n",
    "                                         nn.ELU(),\n",
    "                                         nn.MaxPool2d(2),\n",
    "                                        )\n",
    "        self.linear_layers = nn.Sequential(nn.Linear(15488, 500),\n",
    "                                           nn.Linear(500, D_out),\n",
    "                                          )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = Conv2(input_size=image_size, input_channels=channels).cuda()\n",
    "print(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(conv2, 200, 0.01)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(96, 96, 1)))\n",
    "model.add(Convolution2D(24, 5, 5, border_mode=”same”, init=’he_normal’, input_shape=(96, 96, 1), dim_ordering=”tf”))\n",
    "model.add(Activation(“relu”))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode=”valid”))\n",
    "model.add(Convolution2D(36, 5, 5))\n",
    "model.add(Activation(“relu”))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode=”valid”))\n",
    "model.add(Convolution2D(48, 5, 5))\n",
    "model.add(Activation(“relu”))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode=”valid”))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation(“relu”))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode=”valid”))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation(“relu”))\n",
    "model.add(GlobalAveragePooling2D());\n",
    "model.add(Dense(500, activation=”relu”))\n",
    "model.add(Dense(90, activation=”relu”))\n",
    "model.add(Dense(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3(nn.Module):\n",
    "    def __init__(self, input_size, input_channels):\n",
    "        super(Conv3, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "                                         nn.Conv2d(input_channels, 24, (5, 5)),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, stride=2),\n",
    "                                         nn.Conv2d(24, 36, (5, 5)),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, stride=2),\n",
    "                                         nn.Conv2d(36, 48, (5, 5)),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, stride=2),\n",
    "                                         nn.Conv2d(48, 64, (3, 3)),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, stride=2),\n",
    "                                         nn.Conv2d(64, 64, (3, 3)),\n",
    "                                         nn.ReLU(),\n",
    "                                        )\n",
    "        self.linear_layers = nn.Sequential(nn.Linear(64, 500),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(500, 90),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(90, D_out)\n",
    "                                          )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3 = Conv3(input_size=image_size, input_channels=channels).cuda()\n",
    "print(conv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train(conv3, 100, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_network(conv3, 'conv3_4.254.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv4(nn.Module):\n",
    "    def __init__(self, input_size, input_channels):\n",
    "        super(Conv4, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "                                         nn.Conv2d(input_channels, 24, (5, 5)),\n",
    "                                         nn.BatchNorm2d(24),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, stride=2),\n",
    "                                         nn.Conv2d(24, 36, (5, 5)),\n",
    "                                         nn.BatchNorm2d(36),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, stride=2),\n",
    "                                         nn.Conv2d(36, 48, (5, 5)),\n",
    "                                         nn.BatchNorm2d(48),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, stride=2),\n",
    "                                         nn.Conv2d(48, 64, (3, 3)),\n",
    "                                         nn.BatchNorm2d(64),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, stride=2),\n",
    "                                         nn.Conv2d(64, 64, (3, 3)),\n",
    "                                         nn.BatchNorm2d(64),\n",
    "                                         nn.ReLU(),\n",
    "                                        )\n",
    "        self.linear_layers = nn.Sequential(nn.Linear(64, 500),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(500, 90),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(90, D_out)\n",
    "                                          )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv4 = Conv4(input_size=image_size, input_channels=channels).cuda()\n",
    "print(conv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train(conv4, 100, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv5(nn.Module):\n",
    "    def __init__(self, input_size, input_channels):\n",
    "        super(Conv5, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "                                         nn.Conv2d(input_channels, 24, (3, 3)),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, stride=1),\n",
    "                                         nn.Conv2d(24, 36, (3, 3)),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, stride=1),\n",
    "                                         nn.Conv2d(36, 48, (3, 3)),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, stride=1),\n",
    "                                         nn.Conv2d(48, 64, (3, 3)),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, stride=1),\n",
    "                                         nn.Conv2d(64, 64, (3, 3)),\n",
    "                                         nn.ReLU(),\n",
    "                                        )\n",
    "        self.linear_layers = nn.Sequential(nn.Linear(430336, 700),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(700, 90),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(90, D_out)\n",
    "                                          )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(x.shape)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv5(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 24, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
      "    (3): Conv2d(24, 36, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
      "    (6): Conv2d(36, 48, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
      "    (9): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
      "    (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (13): ReLU()\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=430336, out_features=700, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=700, out_features=90, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=90, out_features=136, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "conv5 = Conv5(input_size=image_size, input_channels=channels).cuda()\n",
    "print(conv5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-bf8c2b3254b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-c8bdf1eaf13a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, epochs, learning_rate, loss, optim)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0mloss_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maksim/Remote/venv36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-47e69542a5fc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maksim/Remote/venv36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maksim/Remote/venv36/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maksim/Remote/venv36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maksim/Remote/venv36/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "train(conv5, 100, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
